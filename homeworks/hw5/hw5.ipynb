{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 5: The Normal Distribution and the Central Limit Theorem\n",
    "\n",
    "## Due Friday, July 25th at 11:59PM\n",
    "\n",
    "Welcome to Homework 5! This homework will cover:\n",
    "\n",
    "* [CIT 14.2](https://www.inferentialthinking.com/chapters/14/2/Variability.html): Variability\n",
    "* [CIT 14.3](https://www.inferentialthinking.com/chapters/14/3/SD_and_the_Normal_Curve.html): The Standard Deviation (SD) and the Normal Curve \n",
    "* [CIT 14.4](https://www.inferentialthinking.com/chapters/14/4/Central_Limit_Theorem.html): The Central Limit Theorem\n",
    "* [CIT 14.5](https://www.inferentialthinking.com/chapters/14/5/Variability_of_the_Sample_Mean.html): The Variability of the Sample Mean\n",
    "* [CIT 14.6](https://inferentialthinking.com/chapters/14/6/Choosing_a_Sample_Size.html): Choosing a Sample Size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "Remember to start early and submit often.\n",
    "\n",
    "**Important**: For homeworks, the `otter` tests don't usually tell you that your answer is correct. More often, they help catch careless mistakes. It's up to you to ensure that your answer is correct. If you're not sure, ask someone (not for the answer, but for some guidance about your approach). These are great questions for office hours (see the schedule on the [Calendar](https://dsc10.com/calendar)) or Campuswire. Directly sharing answers is not okay, but discussing problems with the course staff or with other students is encouraged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Please don't change this cell, but do make sure to run it\n",
    "import babypandas as bpd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import otter\n",
    "grader = otter.Notebook()\n",
    "\n",
    "from IPython.display import IFrame\n",
    "def show_clt_slides():\n",
    "    src = \"https://docs.google.com/presentation/d/e/2PACX-1vTcJd3U1H1KoXqBFcWGKFUPjZbeW4oiNZZLCFY8jqvSDsl4L1rRTg7980nPs1TGCAecYKUZxH5MZIBh/embed?start=false&loop=false&delayms=3000&rm=minimal\"\n",
    "    width = 700\n",
    "    height = 370\n",
    "    display(IFrame(src, width, height))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Testing the Central Limit Theorem: Coin Flips and Marvel Character Appearances 🦸\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Central Limit Theorem tells us that the probability distribution of the sum or mean of a large random sample drawn with replacement is roughly normal, *regardless of the distribution of the population from which the sample is drawn*.\n",
    "\n",
    "That's a pretty big claim, but the theorem doesn't stop there. It further states that, if we're using the mean as our statistic, the standard deviation of this normal distribution is given by $$\\text{SD of Distribution of Possible Sample Means} = \\frac{\\text{Population SD}}{\\sqrt{\\text{sample size}}}$$\n",
    "\n",
    " In other words, suppose we start with *any distribution* that has standard deviation $\\sigma$, take a sample of size $n$ (where $n$ is a large number) from that distribution with replacement, and compute the mean of that sample. If we repeat this procedure many times, then those sample means will have a normal distribution with standard deviation $\\frac{\\sigma}{\\sqrt{n}}$.\n",
    "\n",
    "That's an even bigger claim than the first one! The proof of the theorem is beyond the scope of this class, but we've seen examples in lecture of this formula in action, such as when we looked at flight delay data.\n",
    "\n",
    "Run the cell below to see a short presentation that describes the CLT at a high level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "show_clt_slides()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem, we will be exploring some new data to see the CLT in action."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CLT only applies when sample sizes are \"sufficiently large.\" This isn't a very precise statement. Is 10 large?  How about 50?  The truth is that it depends both on the original population distribution and just how \"normal\" you want the result to look. Let's use a simulation to get a feel for how the distribution of the sample mean changes as the sample size increases.\n",
    "\n",
    "Consider a coin flip. If we say tails is 0 and heads is 1, then there's a 50% chance of getting a 0 and a 50% chance of getting a 1. A histogram of this distribution is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    bpd.DataFrame().assign(outcomes=[0, 1])\n",
    "    .plot(kind='hist', density=True, bins=[-0.5, 0.5, 1.5], ec='w')\n",
    ")\n",
    "plt.xticks([0, 1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This distribution is not roughly normal!\n",
    "\n",
    "The act of flipping a coin many times and computing the proportion of heads is equivalent to drawing a large sample from the above distribution with replacement and computing its mean. Since the proportion of heads in a sample of coin tosses is equal to the mean of that sample, the Central Limit Theorem should apply if we repeatedly toss many coins and compute the proportion of tosses that were heads. Let's try it out and see for ourselves!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.1.** Complete the implementation of the function `simulate_sample_n`. It should take in a sample size, `n`, and should repeat, 5000 times, the process of:\n",
    "- simulating `n` flips of a fair coin, and\n",
    "- counting the proportion of flips that were heads.\n",
    "\n",
    "`simulate_sample_n` should return an array that contains 5000 sample proportions, using the process outlined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def simulate_sample_n(n):\n",
    "    ...\n",
    "simulate_sample_n(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below will use the function you just defined to plot the empirical distribution of the sample mean for several different sample sizes. We saw something similar in [Lecture 17](https://dsc10.com/resources/lectures/lec17/lec17.html#Changing-the-sample-size)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bins = np.arange(-0.01, 1.05, 0.02)\n",
    "\n",
    "for sample_size in np.array([2, 5, 10, 20, 50, 100, 200, 400]):\n",
    "    bpd.DataFrame().assign(**{'Sample_Size:{}'.format(sample_size) : simulate_sample_n(sample_size)}) \\\n",
    "                   .plot(kind='hist', density=True, ec='w', bins=bins, \n",
    "                         title=f'Sample Size {sample_size}', legend=None, figsize=(5, 3));\n",
    "    plt.xlim(-0.01, 1.05)\n",
    "    plt.ylim(0, 25);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that even for samples of size 10, the distribution of sample proportions looks roughly bell-shaped. When we increase the sample size to 50, the resulting distribution looks quite bell-shaped. Note also that as the sample sizes increases, the distributions of sample proportions become narrower."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will test the second claim of the CLT: that the SD of the distribution of the sample mean is the SD of the original distribution, divided by the square root of the sample size.\n",
    "\n",
    "$$\\text{SD of Distribution of Possible Sample Means} = \\frac{\\text{Population SD}}{\\sqrt{\\text{sample size}}}$$\n",
    "\n",
    "To do this, we'll work with a dataset of Marvel characters' total number of appearances in the Marvel Comics' canon. Below, we save this data in the `marvel_pop` DataFrame. We'll treat `marvel_pop` as our population, and we'll take samples directly from it. We've computed the standard deviation of the number of Marvel character appearances for you; you will need to use it in the next question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marvel_pop = bpd.read_csv('data/marvel.csv').set_index('Name')\n",
    "marvel_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marvel_pop_std = np.std(marvel_pop.get('Appearances'))\n",
    "marvel_pop_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.2.** Complete the implementation of the function `predict_sd`. It should take in a sample size `n` and return the predicted standard deviation (according to the CLT) of the sample mean's distribution, for samples of size `n` taken from the `marvel_pop` DataFrame.\n",
    "\n",
    "***Hint:*** **Do not** use or modify your code from `simulate_sample_n`. You should not actually take any samples to answer this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sd(n):\n",
    "    ...\n",
    "\n",
    "predict_sd(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.3.** Complete the implementation of the function `empirical_sd`. It should take in a sample size `n`, draw 1,000 samples of size `n` from `marvel_pop` with replacement, calculate the mean of each sample, and return the **standard deviation of the distribution of the sample means**.\n",
    "\n",
    "***Hint:*** This function will be similar to the `simulate_sample_n` function you wrote earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def empirical_sd(n): \n",
    "    sample_means = np.array([])\n",
    "    ...\n",
    "    return np.std(sample_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below will plot the predicted SDs (computed by your `predict_sd` function) and empirical SDs (computed by your `empirical_sd` function) for various sample sizes. It may take a few moments to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sd_df = bpd.DataFrame().assign(Sample_Size = np.arange(10, 101, 10))\n",
    "predicted = sd_df.get('Sample_Size').apply(predict_sd)\n",
    "empirical = sd_df.get('Sample_Size').apply(empirical_sd)\n",
    "sd_df = sd_df.assign(Predicted_SD = predicted, Empirical_SD = empirical)\n",
    "ax = sd_df.plot(kind='scatter',x='Sample_Size', y='Empirical_SD',label='Empirical_SD', color='red', alpha=0.6, s=100, figsize=(10, 5), legend=False);\n",
    "ax = sd_df.plot(kind='scatter',x='Sample_Size', y='Predicted_SD',label='Predicted_SD', color='blue', alpha=0.6, s=100, ax=ax, legend=False)\n",
    "ax.set_ylabel('Standard Deviation');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that the formula $$\\text{SD of Distribution of Possible Sample Means} = \\frac{\\text{Population SD}}{\\sqrt{\\text{sample size}}}$$ matches what we see in practice!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. UFO Sightings  🛸👽\n",
    "<center><img src=\"./images/ufo.jpg\" width=300/></center>\n",
    "\n",
    "\n",
    "Have you ever looked up into the night sky and seen something you couldn't quite identify? If so, you found yourself an unidentified flying object (UFO). The [National UFO Reporting Center](https://nuforc.org/) collects thousands of reports of UFO sightings each year, and tries to corroborate these reports. It turns out that many of the \"unidentified\" objects actually *can* be identified by experts as satellites, rockets, planets, and other well-understood phenomena. (*But can they all?* 🤷‍♂️)\n",
    "\n",
    "The National UFO Reporting Center publishes a [database of UFO reports](https://nuforc.org/databank/). We've downloaded the data corresponding to UFO sightings in California since the year 2000. The cell below loads this data into a DataFrame called `ufo_sightings`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo_sightings = bpd.read_csv('data/ufo.csv')\n",
    "ufo_sightings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When people submit a UFO report to the National UFO Reporting Center, they fill out an [online form](https://nuforc.org/report-a-ufo/) that asks for details of the UFO sighting, such as their location, any witnesses, and characteristics of the UFO. A portion of the form is shown below.\n",
    "\n",
    "</br>\n",
    "<center><img src=\"./images/characteristics.jpg\" width=400/></center>\n",
    "\n",
    "On the reporting form, reporters are also asked to select a `'shape'` of the UFO they saw. They select this shape from a dropdown menu with a limited set of choices. Let's see which UFO shapes are most commonly reported in California.\n",
    "\n",
    "In the cell below, we compute the distribution of the `'shape'` column in `ufo_sightings`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ufo_shapes = ufo_sightings.groupby('shape').count()\n",
    "ufo_shapes = (ufo_shapes.assign(count=ufo_shapes.get('comments'))\n",
    "                        .sort_values(by='count', ascending=False)\n",
    "                        .get(['count']))\n",
    "ufo_shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the data, the most commonly reported UFO shape is `'Light'`, with 2808 sightings. The next cell calculates this as a proportion of the total sightings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ufo_shapes.get('count').loc['Light']/ufo_shapes.get('count').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem, we'll treat `ufo_sightings` as our population of UFO sightings in California. We'll repeatedly draw samples from this population to compute two statistics — the sample proportion of each `'shape'` and the sample count of each `'shape'`. Our goal is to better understand the relationship between sample proportions, sample counts, and full distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.1.** 10,000 times, draw a [**simple random sample**](https://dsc10.com/resources/lectures/lec13/lec13.html#Simple-random-sample) of 200 sightings from the `ufo_sightings` DataFrame. For each sample, calculate the proportion of sightings with a `'shape'` of `'Light'`. Store all 10,000 calculated proportions in the array `props`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "props = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you've defined `props`, run the following cell to see the distribution of values in `props`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpd.DataFrame().assign(props=props).plot(kind='hist', density=True, ec='w', bins=11, figsize=(10, 5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2.** What _should_ the mean of `props` be, according to the Central Limit Theorem? Store this value in `theoretical_props_mean`. You should not access the data in `props` when calculating `theoretical_props_mean`, because `props` contains the empirical results of an experiment; instead, only refer to `ufo_sightings`. \n",
    "\n",
    "Then, calculate the actual mean of `props` and store this value in `actual_props_mean`. Here, you should refer to `props`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "theoretical_props_mean = ...\n",
    "actual_props_mean = ...\n",
    "\n",
    "# Don't change the following line.\n",
    "print(f'The Central Limit Theorem states that the mean of `props` should be {theoretical_props_mean}.\\nThe actual mean of `props` is {actual_props_mean}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.3.** Again, 10,000 times, draw a simple random sample of 200 sightings from the population of UFO sightings in `ufo_sightings`. This time, for each sample, compute the **number** of sightings with a `'shape'` of `'Light'`. Store all 10,000 counts in the array `counts`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "counts = ...\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you've defined `counts`, run the following cell to see the distribution of values in `counts`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpd.DataFrame().assign(counts=counts).plot(kind='hist', density=True, ec='w', bins=11, figsize=(10, 5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.4.** What _should_ the mean of `counts` be, according to the Central Limit Theorem? Store this value in `theoretical_counts_mean`. Again, you should not access the data in `counts` when calculating `theoretical_counts_mean`; instead, only refer to `ufo_sightings`.\n",
    "\n",
    "Then, calculate the actual mean of `counts` and store this value in `actual_counts_mean`. Here, you should refer to `counts`.\n",
    "\n",
    "***Hint:*** A count is not a mean, so the Central Limit Theorem as we've seen it does not *directly* apply. However, you can use `theoretical_props_mean` from Question 2.2 to help you find `theoretical_counts_mean`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "theoretical_counts_mean = ...\n",
    "actual_counts_mean = ...\n",
    "\n",
    "# Don't change the following line.\n",
    "print(f'The Central Limit Theorem states that the mean of `counts` should be {theoretical_counts_mean}.\\nThe actual mean of `counts` is {actual_counts_mean}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.5.** Let's explore how the histogram of counts changes when we take samples of different sizes. \n",
    "\n",
    "Complete the implementation of the function `count_shapes`. It should take in an integer `size` and do the following:\n",
    "- 10,000 times, draw a simple random sample of the given `size` from `ufo_sightings`.\n",
    "- For each sample, calculate the number of sightings with a `'shape'` of `'Light'`.\n",
    "- Return an array with these 10,000 counts.\n",
    "\n",
    "This requires generalizing your code from Question 2.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_types(size):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below will use the function you just defined to plot the empirical distribution of the count of UFO sightings with a `'shape'` of `'Light'`, for several different sample sizes. It may take a few moments to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for sample_size in [25, 50, 100, 200]:\n",
    "    bpd.DataFrame().assign(types=count_types(sample_size)) \\\n",
    "                   .plot(kind='hist', density=True, ec='w', bins = np.arange(0, 100, 2), \n",
    "                         title=f'Sample Size {sample_size}', legend=None, figsize=(5, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.6.** Using the plots above, what do you notice about the relationship between sample size and the mean of the empirical distribution of the count of UFO sightings with a `'shape'` of `'Light'`? Similarly, what do you notice about the relationship between sample size and the standard deviation of the empirical distribution of the count of UFO sightings with a `'shape'` of `'Light'`? \n",
    "\n",
    "Assign `q2_6` to a **list** of numbers 1 through 4 corresponding to the true statements below.\n",
    "1. As the sample size increases, the mean of the distribution of counts increases.\n",
    "1. As the sample size increases, the mean of the distribution of counts decreases.\n",
    "1. As the sample size increases, the standard deviation of the distribution of counts increases.\n",
    "1. As the sample size increases, the standard deviation of the distribution of counts decreases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q2_6 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer to the last question may surprise you: the distribution of sample counts behaves **differently** than the distribution of sample means. For sample means, a bigger sample allows you to estimate the population mean more precisely. For sample counts, the bigger the sample you have, the more variety is possible in the count. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Trash Talk 🗑"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The city of San Diego is in the midst of implementing a new fee for residential trash collection, a service which is currently provided for free. \n",
    "\n",
    "A state law known as [Proposition 218](https://www.kpbs.org/news/politics/2025/03/12/how-a-decades-old-state-law-can-stop-a-trash-fee-for-san-diegans) says that if enough residents submit a written protest of the fee, the city will not be allowed to implement the fee. The requirement is that a majority, or more than half, of the 500,000 households in San Diego need to submit the written protest for Proposition 218 to block the fee.\n",
    "\n",
    "Janine is curious about whether her fellow San Diego residents will go through the effort of submitting a written protest. She randomly samples 150 households to and asks them whether they will submit a written protest. Her results are shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell, but don't change it.\n",
    "survey = bpd.DataFrame().assign(\n",
    "    Vote=np.array([\"Yes\", \"No\"]),\n",
    "    Count=np.array([68, 82]))\n",
    "sample_size = survey.get(\"Count\").sum()\n",
    "survey_results = survey.assign(\n",
    "    Proportion=survey.get(\"Count\") / sample_size)\n",
    "survey_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, Janine uses 5,000 bootstrap resamples to compute a confidence interval for the proportion of all San Diego households that will submit a written protest.  Run the next cell to see the empirical distribution of this proportion in the 5,000 resamples.\n",
    "\n",
    "Note that we're using `np.random.multinomial` to do the resampling here, since each element of the resample is either 1 (`'Yes'`) or 0 (`'No'`) with known probabilities. This accomplishes the same thing as using `.sample` with `replace=True`, but is much faster. The 5,000 bootstrapped proportions are stored in an array called `yes_proportions`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yes_proportions = np.array([])\n",
    "for i in np.arange(5000):\n",
    "    resample = np.random.multinomial(sample_size, survey_results.get('Proportion')) / sample_size\n",
    "    yes_proportions = np.append(yes_proportions, resample[0])\n",
    "bpd.DataFrame().assign(yes_proportions = yes_proportions).plot(kind='hist', density=True, ec='w', figsize=(10,5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall, the Central Limit Theorem says\n",
    "\n",
    "$$\\text{SD of Distribution of Possible Sample Means} = \\frac{\\text{Population SD}}{\\sqrt{\\text{sample size}}}$$\n",
    "\n",
    "Furthermore, in any collection of numbers where the only unique values are 0 and 1, there is a simple formula for the standard deviation of the collection:\n",
    "\n",
    "$$\\text{SD of Collection of 0s and 1s} = \\sqrt{(\\text{Proportion of 0s in Collection}) \\times (\\text{Proportion of 1s in Collection})}$$\n",
    "\n",
    "Note that samples and populations are both possible examples of \"collections.\" \n",
    "\n",
    "(You're not responsible for deriving this formula, but if you're curious, it's possible to do so just by using the definition of standard deviation and a little algebra!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since you'll need the numbers in it to answer Question 3.1, here's `survey_results` once again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.1.**\n",
    "**Without accessing the data in `yes_proportions` in any way**, compute an approximation of the standard deviation of the array `yes_proportions` and assign it to the variable `approximate_sd`.\n",
    "\n",
    "Instead of using `yes_proportions` directly, use **both** the Central Limit Theorem and the standard deviation formula above. Since you don't know the true proportions of 0s and 1s in the population, use the proportions in the sample instead (since they're likely to be similar), which are provided in the DataFrame `survey_results`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approximate_sd = ...\n",
    "approximate_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.2.** Compute the actual standard deviation of the array `yes_proportions`. Your answer should be close to your answer from Question 3.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_sd = ...\n",
    "exact_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since you'll need the numbers in it to answer Question 3.3, here's `survey_results` once again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.3.**\n",
    "**Without accessing `yes_proportions` in any way**, compute an approximate 95% confidence interval for the proportion of all San Diego households that will submit a written protest.\n",
    "\n",
    "The cell below `grader.check(\"q3_3\")` draws your interval in gold below the histogram of `yes_proportions`; use that to verify that your answer looks right.\n",
    "\n",
    "***Hint:*** In the past, we've used `np.percentile` on the array of bootstrapped estimates to find the bounds for the confidence interval. Now, **we're not allowed to use the bootstrapped distribution**, so we can't do it that way. But we don't need to:\n",
    "- The Central Limit Theorem tells us that the distribution of the sample mean is normal with a certain mean and standard deviation.\n",
    "- `survey_results` provides an estimate of this mean; you can use that number here.\n",
    "- In Question 3.1, you estimated this standard deviation (without using `yes_proportions`) and saved it to the variable `approximate_sd`; you can use that here as well.\n",
    "- We also know that 95% of the area of the normal distribution falls within a certain number of standard deviations from the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_limit = ...\n",
    "upper_limit = ...\n",
    "\n",
    "# Your interval is:\n",
    "[lower_limit, upper_limit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to plot your confidence interval.\n",
    "bpd.DataFrame().assign(yes_proportions = yes_proportions).plot(kind='hist', density=True, ec='w', figsize=(10, 5));\n",
    "plt.plot([upper_limit, lower_limit], [0, 0], color='gold', linewidth=10, label='Normal CI');\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your confidence interval should contain the value 0.5, and values even larger than 0.5, meaning it's certainly plausible that enough households will submit protests in order to block the trash fee. \n",
    "\n",
    "However, the confidence interval is pretty wide and therefore not that informative. Janine decides to redo her survey with a larger sample size to estimate with greater precision the proportion of all San Diego households that will protest the trash fees. She wants the **standard deviation of the distribution of the sample mean to be 0.01** (or less).  She will need to take a new sample that's large enough to achieve that. Polling is time-consuming, so the sample also shouldn't be bigger than necessary.\n",
    "\n",
    "Instead of making the conservative assumption that the population standard deviation is 0.5 (the largest possible SD of a collection of 0s and 1s), she decides to assume that it's equal to the standard deviation of her first sample. That is,\n",
    "\n",
    "$$\\text{Population SD} \\approx \\text{Sample SD} = \\sqrt{(\\text{Proportion of 0s in Sample}) \\times (\\text{Proportion of 1s in Sample})}$$\n",
    "\n",
    "Under that assumption, she computes the smallest sample size necessary in order to be confident that the standard deviation of the distribution of the sample mean is at most 0.01."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.4.**\n",
    "What sample size did she find? Assign your answer to the variable `new_sample_size`, which should be of type `int`.\n",
    "\n",
    "Use the fact that $$\\text{SD of Distribution of Possible Sample Means} = \\frac{\\text{Population SD}}{\\sqrt{\\text{sample size}}}$$\n",
    "\n",
    "***Hints:***\n",
    "- There is only one unknown in the equation above.\n",
    "- Think about how you should round your answer to satisfy the constraints of the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_sample_size = ...\n",
    "new_sample_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.5.** Suppose Janine wants to be even more precise and take a sample of sufficient size such that the standard deviation of the sample mean distribution is 0.005. Is it possible for her to do this? Choose the best answer and explanation, then assign `q3_5` to either 1, 2, 3, or 4.\n",
    "\n",
    "1. Yes. She can repeat the sample again until she comes across a sample with a standard deviation of 0.005.\n",
    "1. Yes. Since the 0.005 is half of 0.01, the required sample size is about twice as large as `new_sample_size`.\n",
    "1. Yes. Since the 0.005 is half of 0.01, the required sample size is about four times as large as `new_sample_size`.\n",
    "1. No, the sample size required to reach that sample mean standard deviation is larger than the number of households in San Diego (500,000).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q3_5 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Key Concepts 🔑"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.1.** How do we convert the value 34 to standard units if it comes from a dataset where the mean is 20 and the standard deviation is 3? Assign `q4_1` to either 1, 2, 3, or 4.\n",
    "\n",
    "\n",
    "\n",
    "1.\n",
    "$\\dfrac{20-34}{3}$\n",
    "\n",
    "2.\n",
    "$\\dfrac{34-20}{3}$\n",
    "\n",
    "3.\n",
    "$\\dfrac{{34-20}}{\\sqrt{3}}$\n",
    "\n",
    "4.\n",
    "$\\dfrac{({20-34})^2}{3}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q4_1 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.2.** According to Chebyshev's inequality, for any dataset, at least half of the data falls within how many standard deviations of the mean? Assign the **smallest** correct answer to `q4_2`.\n",
    "\n",
    "1. 1.35\n",
    "2. 1.40\n",
    "3. 1.45\n",
    "4. 1.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q4_2 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.3.** Assign `q4_3` to a **list** of all statements below that are **always** true.\n",
    "\n",
    "\n",
    "\n",
    "1. An empirical histogram of the sample mean of a large random sample drawn with replacement from a population will be roughly normal.\n",
    "1. An empirical histogram of the sample median of a large random sample drawn with replacement from a population will be roughly normal.\n",
    "1. If we know the mean and SD of a distribution, we can calculate a 68% confidence interval by stepping out one standard deviation from the mean in both directions.\n",
    "1. For any distribution, 95% of the data falls within two standard deviations of the mean.\n",
    "1. For any distribution, at least 95% of the data falls within five standard deviations of the mean.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q4_3 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.4.** Consider drawing a large random sample with replacement from some population. Let $x$ be the sample size such that the standard deviation of the distribution of sample means is 20. Choose the sample size required to guarantee that the standard deviation of the distribution of sample means is no more than 5. Assign `q4_4` to either 1, 2, 3, or 4.\n",
    "\n",
    "1. $2x$\n",
    "1. $4x$\n",
    "1. $8x$\n",
    "1. $16x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q4_4 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finish Line: Almost there, but make sure to follow the steps below to submit! 🏁\n",
    "\n",
    "**_Citations:_** Did you use any generative artificial intelligence tools to assist you on this assignment? If so, please state, for each tool you used, the name of the tool (ex. ChatGPT) and the problem(s) in this assignment where you used the tool for help."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"color:Maroon;background-color:Maroon;border:0 none; height: 3px;\">\n",
    "\n",
    "Please cite tools here.\n",
    "\n",
    "<hr style=\"color:Maroon;background-color:Maroon;border:0 none; height: 3px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You are done with Homework 5, the second-to-last homework of the quarter!\n",
    "\n",
    "To submit your assignment:\n",
    "\n",
    "1. Select `Kernel -> Restart & Run All` to ensure that you have executed all cells, including the test cells.\n",
    "1. Read through the notebook to make sure everything is fine and all tests passed.\n",
    "1. Run the cell below to run all tests, and make sure that they all pass.\n",
    "1. Download your notebook using `File -> Download as -> Notebook (.ipynb)`, then upload your notebook to Gradescope.\n",
    "1. Stick around while the Gradescope autograder grades your work. Make sure you see that all tests have passed on Gradescope.\n",
    "1. Check that you have a confirmation email from Gradescope and save it as proof of your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
